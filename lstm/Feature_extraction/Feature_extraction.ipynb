{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a71fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import librosa_trans\n",
    "import re\n",
    "from IPython.display import clear_output, display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aae34706",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_path = os.path.abspath('./')\n",
    "test_list = ['test']\n",
    "data = pd.DataFrame()\n",
    "for test in test_list:\n",
    "    dir_path = sorted(os.listdir(os.path.join(sound_path, test)))\n",
    "    for file in iter(dir_path):\n",
    "        if file.endswith(\".wav\"):\n",
    "            time_detail = re.search( r'(.*)_(.*)_(.*)_(.*)-(.*).wav', file).group(4)\n",
    "           # time_detail = re.search( r'(.*)-(.*).wav', file).group(1)\n",
    "            date = datetime.strptime(time_detail, '%Y%m%d')\n",
    "            #if date>=datetime.strptime('20221017', '%Y%m%d'):\n",
    "            #    data=data.append({'path':str(os.path.join(sound_path,test,file)),'id':test,'district':'north','state':'Poision'}, ignore_index=True)\n",
    "           # else:\n",
    "           #     data=data.append({'path':str(os.path.join(sound_path,test,file)),'id':test,'district':'north','state':'Normal'}, ignore_index=True)\n",
    "             if date>=datetime.strptime('20221017', '%Y%m%d') and date<=datetime.strptime('20221017', '%Y%m%d'):\n",
    "                data=data.append({'path':str(os.path.join(sound_path,test,file)),'id':test,'district':'north','state':'Poision'}, ignore_index=True)\n",
    "            elif date>=datetime.strptime('20221017', '%Y%m%d') and date<=datetime.strptime('20221017', '%Y%m%d'):\n",
    "                data=data.append({'path':str(os.path.join(sound_path,test,file)),'id':test,'district':'north','state':'Normal'}, ignore_index=True)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45186061",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./data/test.csv',index_label=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05bcedd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/TOSHIBA EXT/north/q-1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1be29eecfd22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolony\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolony_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mdir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msound_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolony\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtime_detail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34mr'(.*).wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/TOSHIBA EXT/north/q-1'"
     ]
    }
   ],
   "source": [
    "'''# old data process\n",
    "sound_path = os.path.abspath('/Volumes/TOSHIBA EXT/old/test')\n",
    "normal_list=['normal','normal_1','normal_2']\n",
    "queenless_list=['queenless','queenless_1','queenless_2']\n",
    "end_row=[0]\n",
    "\n",
    "data=pd.DataFrame()\n",
    "\n",
    "for normal in normal_list:\n",
    "    dir_path = sorted(os.listdir(os.path.join(sound_path, normal)))\n",
    "    for file in iter(dir_path):\n",
    "        if file.endswith(\".wav\"):\n",
    "            time_detail = re.search( r'(.*).wav', file).group(1)\n",
    "            int_time = [int(time_index) for time_index in time_detail.split('_')]\n",
    "            time_split = datetime.strftime( datetime(*int_time) ,'%Y-%m-%d %H:%M:%S')\n",
    "            data=data.append({'date':time_split,'path':str(os.path.join(sound_path, normal,file)),'id':normal,'district':'north','state':'normal'}, ignore_index=True)\n",
    "    end_row.append(len(data)) \n",
    "    \n",
    "    \n",
    "for queenless in queenless_list:\n",
    "    dir_path = sorted(os.listdir(os.path.join(sound_path, queenless)))\n",
    "    for file in iter(dir_path):\n",
    "        if file.endswith(\".wav\"):\n",
    "            time_detail = re.search( r'(.*).wav', file).group(1)\n",
    "            int_time = [int(time_index) for time_index in time_detail.split('_')]\n",
    "            time_split = datetime.strftime( datetime(*int_time) ,'%Y-%m-%d %H:%M:%S')\n",
    "            data=data.append({'date':time_split,'path':str(os.path.join(sound_path, normal,file)),'id':normal,'district':'north','state':'normal'}, ignore_index=True)\n",
    "    end_row.append(len(data)) '''\n",
    "\n",
    "\n",
    "# new data process\n",
    "sound_path = os.path.abspath('/Volumes/TOSHIBA EXT/north')\n",
    "colony_list = ['q-1','q-2','q-3','q-4']\n",
    "\n",
    "for colony in colony_list:\n",
    "    dir_path = sorted(os.listdir(os.path.join(sound_path, colony)))\n",
    "    for file in dir_path:\n",
    "        time_detail = re.search( r'(.*).wav', file).group(1)\n",
    "        date,time = time_detail.split('-')\n",
    "        time_split = datetime.strptime(date+time,'%Y%m%d%H%M%S')\n",
    "        if int(date+time)>202108201130:\n",
    "            data=data.append({'date':time_split,'path':os.path.join(sound_path,colony,file),'id':colony,'district':'north','state':'queenless'}, ignore_index=True)\n",
    "        else:\n",
    "            data=data.append({'date':time_split,'path':os.path.join(dir_path,file),'id':colony,'district':'north','state':'normal'}, ignore_index=True)\n",
    "\n",
    "    end_row.append(len(data))\n",
    "data.to_csv('./data/datalist.csv',index_label=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b6355cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata length: 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>district</th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>north</td>\n",
       "      <td>test</td>\n",
       "      <td>/home/yiying/Documents/data/lstm/test/Yunlin_n...</td>\n",
       "      <td>Poision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>north</td>\n",
       "      <td>test</td>\n",
       "      <td>/home/yiying/Documents/data/lstm/test/Yunlin_n...</td>\n",
       "      <td>Poision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>north</td>\n",
       "      <td>test</td>\n",
       "      <td>/home/yiying/Documents/data/lstm/test/Yunlin_n...</td>\n",
       "      <td>Poision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>north</td>\n",
       "      <td>test</td>\n",
       "      <td>/home/yiying/Documents/data/lstm/test/Yunlin_n...</td>\n",
       "      <td>Poision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>north</td>\n",
       "      <td>test</td>\n",
       "      <td>/home/yiying/Documents/data/lstm/test/Yunlin_n...</td>\n",
       "      <td>Poision</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 district    id  \\\n",
       "30          30    north  test   \n",
       "31          31    north  test   \n",
       "32          32    north  test   \n",
       "33          33    north  test   \n",
       "34          34    north  test   \n",
       "\n",
       "                                                 path    state  \n",
       "30  /home/yiying/Documents/data/lstm/test/Yunlin_n...  Poision  \n",
       "31  /home/yiying/Documents/data/lstm/test/Yunlin_n...  Poision  \n",
       "32  /home/yiying/Documents/data/lstm/test/Yunlin_n...  Poision  \n",
       "33  /home/yiying/Documents/data/lstm/test/Yunlin_n...  Poision  \n",
       "34  /home/yiying/Documents/data/lstm/test/Yunlin_n...  Poision  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the metadata from the generated CSV\n",
    "metadata = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# Examine dataframe\n",
    "print(\"Metadata length:\", len(metadata))\n",
    "metadata.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d81fc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 34/35\n",
      "Last file:  /home/yiying/Documents/data/lstm/test/Yunlin_normal_1_20221017-081725.wav\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "labels = []\n",
    "frames_max = 0\n",
    "for index, row in metadata.iloc[0:].iterrows():\n",
    "\n",
    "        file_path = os.path.abspath(str(row[\"path\"]))\n",
    "        colony_label = row[\"id\"]\n",
    "        state_label = row[\"state\"]\n",
    "\n",
    "        # Extract MFCCs (do not add padding)\n",
    "        mfccs = librosa_trans.mfcc_transform(file_path)\n",
    "\n",
    "        # Save current frame count\n",
    "        num_frames = mfccs.shape[1]\n",
    "\n",
    "        # Add row (feature / label)\n",
    "        features.append(mfccs)\n",
    "        labels.append(state_label)\n",
    "\n",
    "        # Update frames maximum\n",
    "        if (num_frames > frames_max):\n",
    "            frames_max = num_frames\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(\"Progress: {}/{}\".format(index,len(metadata)))\n",
    "        print(\"Last file: \", file_path)\n",
    "padded = []\n",
    "\n",
    "# Add padding\n",
    "mfcc_max_padding = frames_max\n",
    "for j in range(len(features)):\n",
    "    size = len(features[j][0])\n",
    "    if (size < mfcc_max_padding):\n",
    "        pad_width = mfcc_max_padding - size\n",
    "        px = np.pad(features[j], \n",
    "                    pad_width=((0, 0), (0, pad_width)), \n",
    "                    mode='constant', \n",
    "                    constant_values=(0,))\n",
    "    else:\n",
    "        px = features[j]\n",
    "\n",
    "    padded.append(px)\n",
    "\n",
    "\n",
    "        # save file\n",
    "\n",
    "X = np.array(padded)\n",
    "y = np.array(labels)\n",
    "\n",
    "\n",
    "# Optionally save the features to disk\n",
    "np.save(f\"./data/test-X-mfcc-augmented\", X)\n",
    "np.save(f\"./data/test-y-mfcc-augmented\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc8d200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "padded = []\n",
    "\n",
    "# Add padding\n",
    "mfcc_max_padding = frames_max\n",
    "for j in range(len(features)):\n",
    "    size = len(features[j][0])\n",
    "    if (size < mfcc_max_padding):\n",
    "        pad_width = mfcc_max_padding - size\n",
    "        px = np.pad(features[j], \n",
    "                    pad_width=((0, 0), (0, pad_width)), \n",
    "                    mode='constant', \n",
    "                    constant_values=(0,))\n",
    "    else:\n",
    "        px = features[j]\n",
    "\n",
    "    padded.append(px)\n",
    "\n",
    "\n",
    "        # save file\n",
    "\n",
    "X = np.array(padded)\n",
    "y = np.array(labels)\n",
    "\n",
    "\n",
    "# Optionally save the features to disk\n",
    "np.save(f\"./data/flu4-X-mfcc-augmented\", X)\n",
    "np.save(f\"./data/flu4-y-mfcc-augmented\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb923d94",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'end_row' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0d1cc6bd0397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'end_row' is not defined"
     ]
    }
   ],
   "source": [
    "# MFCC input feature extraction\n",
    "\n",
    "# Iterate through all audio files and extract MFCC\n",
    "\n",
    "\n",
    "for i in range(len(end_row)-1):\n",
    "    features = []\n",
    "    labels = []\n",
    "    colonies = []\n",
    "    frames_max = 0\n",
    "    counter = 0\n",
    "    total_samples = end_row[i+1]-end_row[i]\n",
    "    n_mfcc = 40\n",
    "    \n",
    "    # transform to MFCC\n",
    "    for index, row in metadata.iloc[end_row[i]:end_row[i+1]].iterrows():\n",
    "        \n",
    "\n",
    "        file_path = os.path.abspath(str(row[\"path\"]))\n",
    "        colony_label = row[\"id\"]\n",
    "        state_label = row[\"state\"]\n",
    "        print(file_path)\n",
    "\n",
    "        # Extract MFCCs (do not add padding)\n",
    "        mfccs = librosa_trans.mfcc_transform(file_path)\n",
    "\n",
    "        # Save current frame count\n",
    "        num_frames = mfccs.shape[1]\n",
    "\n",
    "        # Add row (feature / label)\n",
    "        features.append(mfccs)\n",
    "        labels.append(state_label)\n",
    "        colonies.append(colony_label)\n",
    "\n",
    "        # Update frames maximum\n",
    "        if (num_frames > frames_max):\n",
    "            frames_max = num_frames\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(\"Progress: {}/{}\".format(index+1-end_row[i],total_samples))\n",
    "        print(\"Last file: \", file_path)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    print(\"Finished: {}/{}\".format(index+1-end_row[i], total_samples))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # padding to max_length\n",
    "    \n",
    "    padded = []\n",
    "\n",
    "    # Add padding\n",
    "    mfcc_max_padding = frames_max\n",
    "    for j in range(len(features)):\n",
    "        size = len(features[j][0])\n",
    "        if (size < mfcc_max_padding):\n",
    "            pad_width = mfcc_max_padding - size\n",
    "            px = np.pad(features[j], \n",
    "                        pad_width=((0, 0), (0, pad_width)), \n",
    "                        mode='constant', \n",
    "                        constant_values=(0,))\n",
    "        else:\n",
    "            px = features[j]\n",
    "        \n",
    "        padded.append(px)\n",
    "        \n",
    "        \n",
    "    # save file\n",
    "    \n",
    "    X = np.array(padded)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    # Optionally save the features to disk\n",
    "    np.save(f\"./data/{colonies[i]}-X-mfcc-augmented\", X)\n",
    "    np.save(f\"./data/{colonies[i]}-y-mfcc-augmented\", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "189fa7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add time factor\n",
    "\n",
    "for i in range(len(end_row)-1):\n",
    "    hour =[]\n",
    "    for index, row in metadata.iloc[end_row[i]:end_row[i+1]].iterrows():\n",
    "        time  = re.search(r'.* ([0-9][0-9]):.*',row[\"date\"]).group(1)\n",
    "        colony_label = row[\"id\"]\n",
    "        hour.append(int(time)/23)\n",
    "    \n",
    "    np.save(f\"./data/{colony_label}-time-augmented\", hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e4f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-Mel Spectrogram extraction\n",
    "new_path='/media/yiying'\n",
    "for i in range(len(end_row)-1):\n",
    "    features = []\n",
    "    labels = []\n",
    "    colonies = []\n",
    "    frames_max = 0\n",
    "    counter = 0\n",
    "    total_samples = len(metadata)\n",
    "    n_mels = 40\n",
    "\n",
    "    for index, row in metadata.iloc[end_row[i]:end_row[i+1]].iterrows():\n",
    "        #file_path = os.path.abspath(str(row[\"path\"]))\n",
    "        file_path = new_path+ row[\"path\"]\n",
    "        colony_label = row[\"colony\"]\n",
    "        state_label = row[\"state\"]\n",
    "\n",
    "        # Extract Log-Mel Spectrograms (do not add padding)\n",
    "        mels = librosa_trans.log_mel_spec_transform(file_path, mfcc_max_padding=0, n_mels=n_mels)\n",
    "\n",
    "        # Save current frame count\n",
    "        num_frames = mels.shape[1]\n",
    "\n",
    "        # Add row (feature / label)\n",
    "        features.append(mels)\n",
    "        labels.append(state_label)\n",
    "        colonies.append(colony_label)\n",
    "\n",
    "        # Update frames maximum\n",
    "        if (num_frames > frames_max):\n",
    "            frames_max = num_frames\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(\"Progress: {}/{}\".format(index+1-end_row[i], total_samples))\n",
    "        print(\"Last file: \", file_path)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    print(\"Finished: {}/{}\".format(index+1-end_row[i], total_samples))\n",
    "    \n",
    "    \n",
    "        # padding to max_length\n",
    "    \n",
    "    padded = []\n",
    "\n",
    "    # Add padding\n",
    "    mfcc_max_padding = frames_max\n",
    "    for j in range(len(features)):\n",
    "        size = len(features[j][0])\n",
    "        if (size < mfcc_max_padding):\n",
    "            pad_width = mfcc_max_padding - size\n",
    "            px = np.pad(features[j], \n",
    "                        pad_width=((0, 0), (0, pad_width)), \n",
    "                        mode='constant', \n",
    "                        constant_values=(0,))\n",
    "        else:\n",
    "            px = features[j]\n",
    "        \n",
    "        padded.append(px)\n",
    "        \n",
    "        \n",
    "    # save file\n",
    "    \n",
    "    X = np.array(padded)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    # Optionally save the features to disk\n",
    "    np.save(f\"./data/{colonies[i]}-X-mel_spec-augmented\", X)\n",
    "    np.save(f\"./data/{colonies[i]}-y-mel_spec-augmented\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eaf738",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = []\n",
    "\n",
    "# Add padding\n",
    "mels_max_padding = frames_max\n",
    "for i in range(len(features)):\n",
    "    size = len(features[i][0])\n",
    "    if (size < mels_max_padding):\n",
    "        pad_width = mels_max_padding - size\n",
    "        px = np.pad(features[i], \n",
    "                    pad_width=((0, 0), (0, pad_width)), \n",
    "                    mode='constant', \n",
    "                    constant_values=(0,))\n",
    "    \n",
    "    padded.append(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a061ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in len(end_row)-1:\n",
    "    X = np.array(padded[end_row[i],end_row[i+1]])\n",
    "    y = np.array(padded[end_row[i],end_row[i+1]])\n",
    "\n",
    "    # Optionally save the features to disk\n",
    "    np.save(f\"./data/{colonies[i]}-X-mel_spec-augmented\", X)\n",
    "    np.save(f\"./data/{colonies[i]}-y-mel_spec-augmented\", y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
