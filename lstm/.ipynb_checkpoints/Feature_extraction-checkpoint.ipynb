{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "197e3816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import librosa_trans\n",
    "import re\n",
    "from IPython.display import clear_output, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05bcedd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old data process\n",
    "sound_path = os.path.abspath('/Volumes/TOSHIBA EXT/old/test')\n",
    "normal_list=['normal','normal_1','normal_2']\n",
    "queenless_list=['queenless','queenless_1','queenless_2']\n",
    "end_row=[0]\n",
    "\n",
    "data=pd.DataFrame()\n",
    "\n",
    "for normal in normal_list:\n",
    "    dir_path = sorted(os.listdir(os.path.join(sound_path, normal)))\n",
    "    for file in iter(dir_path):\n",
    "        if file.endswith(\".wav\"):\n",
    "            time_detail = re.search( r'(.*).wav', file).group(1)\n",
    "            int_time = [int(time_index) for time_index in time_detail.split('_')]\n",
    "            time_split = datetime.strftime( datetime(*int_time) ,'%Y-%m-%d %H:%M:%S')\n",
    "            data=data.append({'date':time_split,'path':str(os.path.join(sound_path, normal,file)),'id':normal,'district':'north','state':'normal'}, ignore_index=True)\n",
    "    end_row.append(len(data)) \n",
    "    \n",
    "    \n",
    "for queenless in queenless_list:\n",
    "    dir_path = sorted(os.listdir(os.path.join(sound_path, normal)))\n",
    "    for file in iter(dir_path):\n",
    "        if file.endswith(\".wav\"):\n",
    "            time_detail = re.search( r'(.*).wav', file).group(1)\n",
    "            int_time = [int(time_index) for time_index in time_detail.split('_')]\n",
    "            time_split = datetime.strftime( datetime(*int_time) ,'%Y-%m-%d %H:%M:%S')\n",
    "            data=data.append({'date':time_split,'path':str(os.path.join(sound_path, normal,file)),'id':normal,'district':'north','state':'normal'}, ignore_index=True)\n",
    "    end_row.append(len(data)) \n",
    "\n",
    "\n",
    "# new data process\n",
    "sound_path = os.path.abspath('/Volumes/TOSHIBA EXT/north')\n",
    "colony_list = ['q-1','q-2','q-3','q-4']\n",
    "\n",
    "for colony in colony_list:\n",
    "    dir_path = sorted(os.listdir(os.path.join(sound_path, colony)))\n",
    "    for file in dir_path:\n",
    "        time_detail = re.search( r'(.*).wav', file).group(1)\n",
    "        date,time = time_detail.split('-')\n",
    "        time_split = datetime.strptime(date+time,'%Y%m%d%H%M%S')\n",
    "        if int(date+time)>202108201130:\n",
    "            data=data.append({'date':time_split,'path':os.path.join(sound_path,colony,file),'id':colony,'district':'north','state':'queenless'}, ignore_index=True)\n",
    "        else:\n",
    "            data=data.append({'date':time_split,'path':os.path.join(dir_path,file),'id':colony,'district':'north','state':'normal'}, ignore_index=True)\n",
    "\n",
    "    end_row.append(len(data))\n",
    "data.to_csv('./data/datalist.csv',index_label=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b6355cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata length: 32193\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>district</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32188</th>\n",
       "      <td>32188</td>\n",
       "      <td>2021-08-23 23:54:13</td>\n",
       "      <td>/Volumes/TOSHIBA EXT/north/q-4/20210823-235413...</td>\n",
       "      <td>q-4</td>\n",
       "      <td>north</td>\n",
       "      <td>queenless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32189</th>\n",
       "      <td>32189</td>\n",
       "      <td>2021-08-23 23:55:23</td>\n",
       "      <td>/Volumes/TOSHIBA EXT/north/q-4/20210823-235523...</td>\n",
       "      <td>q-4</td>\n",
       "      <td>north</td>\n",
       "      <td>queenless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32190</th>\n",
       "      <td>32190</td>\n",
       "      <td>2021-08-23 23:56:33</td>\n",
       "      <td>/Volumes/TOSHIBA EXT/north/q-4/20210823-235633...</td>\n",
       "      <td>q-4</td>\n",
       "      <td>north</td>\n",
       "      <td>queenless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32191</th>\n",
       "      <td>32191</td>\n",
       "      <td>2021-08-23 23:57:43</td>\n",
       "      <td>/Volumes/TOSHIBA EXT/north/q-4/20210823-235743...</td>\n",
       "      <td>q-4</td>\n",
       "      <td>north</td>\n",
       "      <td>queenless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32192</th>\n",
       "      <td>32192</td>\n",
       "      <td>2021-08-23 23:58:53</td>\n",
       "      <td>/Volumes/TOSHIBA EXT/north/q-4/20210823-235853...</td>\n",
       "      <td>q-4</td>\n",
       "      <td>north</td>\n",
       "      <td>queenless</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                 date  \\\n",
       "32188       32188  2021-08-23 23:54:13   \n",
       "32189       32189  2021-08-23 23:55:23   \n",
       "32190       32190  2021-08-23 23:56:33   \n",
       "32191       32191  2021-08-23 23:57:43   \n",
       "32192       32192  2021-08-23 23:58:53   \n",
       "\n",
       "                                                    path   id district  \\\n",
       "32188  /Volumes/TOSHIBA EXT/north/q-4/20210823-235413...  q-4    north   \n",
       "32189  /Volumes/TOSHIBA EXT/north/q-4/20210823-235523...  q-4    north   \n",
       "32190  /Volumes/TOSHIBA EXT/north/q-4/20210823-235633...  q-4    north   \n",
       "32191  /Volumes/TOSHIBA EXT/north/q-4/20210823-235743...  q-4    north   \n",
       "32192  /Volumes/TOSHIBA EXT/north/q-4/20210823-235853...  q-4    north   \n",
       "\n",
       "           state  \n",
       "32188  queenless  \n",
       "32189  queenless  \n",
       "32190  queenless  \n",
       "32191  queenless  \n",
       "32192  queenless  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the metadata from the generated CSV\n",
    "metadata = pd.read_csv('./data/datalist.csv')\n",
    "\n",
    "# Examine dataframe\n",
    "print(\"Metadata length:\", len(metadata))\n",
    "metadata.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb923d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 952/952\n",
      "Last file:  /Volumes/TOSHIBA EXT/old/test/normal/2018_05_16_4_5_55.wav\n",
      "Finished: 951/952\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'px' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t6/_p4q17h13vl8ry05fd5xgx180000gn/T/ipykernel_16341/2063416622.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m                         constant_values=(0,))\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mpadded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'px' is not defined"
     ]
    }
   ],
   "source": [
    "# MFCC input feature extraction\n",
    "\n",
    "# Iterate through all audio files and extract MFCC\n",
    "\n",
    "\n",
    "for i in range(len(end_row)-1):\n",
    "    features = []\n",
    "    labels = []\n",
    "    colonies = []\n",
    "    frames_max = 0\n",
    "    counter = 0\n",
    "    total_samples = end_row[i+1]-end_row[i]\n",
    "    n_mfcc = 40\n",
    "    \n",
    "    # transform to MFCC\n",
    "    for index, row in metadata.iloc[end_row[i]:end_row[i+1]].iterrows():\n",
    "        \n",
    "\n",
    "        file_path = os.path.abspath(str(row[\"path\"]))\n",
    "        colony_label = row[\"id\"]\n",
    "        state_label = row[\"state\"]\n",
    "\n",
    "        # Extract MFCCs (do not add padding)\n",
    "        mfccs = librosa_trans.mfcc_transform(file_path)\n",
    "\n",
    "        # Save current frame count\n",
    "        num_frames = mfccs.shape[1]\n",
    "\n",
    "        # Add row (feature / label)\n",
    "        features.append(mfccs)\n",
    "        labels.append(state_label)\n",
    "        colonies.append(colony_label)\n",
    "\n",
    "        # Update frames maximum\n",
    "        if (num_frames > frames_max):\n",
    "            frames_max = num_frames\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(\"Progress: {}/{}\".format(index+1,total_samples))\n",
    "        print(\"Last file: \", file_path)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    print(\"Finished: {}/{}\".format(index, total_samples))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # padding to max_length\n",
    "    \n",
    "    padded = []\n",
    "\n",
    "    # Add padding\n",
    "    mfcc_max_padding = frames_max\n",
    "    for j in range(len(features)):\n",
    "        size = len(features[j][0])\n",
    "        if (size < mfcc_max_padding):\n",
    "            pad_width = mfcc_max_padding - size\n",
    "            px = np.pad(features[j], \n",
    "                        pad_width=((0, 0), (0, pad_width)), \n",
    "                        mode='constant', \n",
    "                        constant_values=(0,))\n",
    "        else:\n",
    "            px = features[j]\n",
    "        \n",
    "        padded.append(px)\n",
    "        \n",
    "        \n",
    "    # save file\n",
    "    \n",
    "    X = np.array(padded)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    # Optionally save the features to disk\n",
    "    np.save(f\"/Volumes/TOSHIBA EXT/north/{colonies[i]}-mfcc-augmented\", X)\n",
    "    np.save(f\"/Volumes/TOSHIBA EXT/north/{colonies[i]}-mfcc-augmented\", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daadb9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bcef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = []\n",
    "\n",
    "# Add padding\n",
    "mfcc_max_padding = frames_max\n",
    "for i in range(len(features)):\n",
    "    size = len(features[i][0])\n",
    "    if (size < mfcc_max_padding):\n",
    "        pad_width = mfcc_max_padding - size\n",
    "        px = np.pad(features[i], \n",
    "                    pad_width=((0, 0), (0, pad_width)), \n",
    "                    mode='constant', \n",
    "                    constant_values=(0,))\n",
    "    \n",
    "    padded.append(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f616c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features (X) and labels (y) to different colony Numpy arrays\n",
    "for i in len(end_row)-1:\n",
    "    X = np.array(padded[end_row[i],end_row[i+1]])\n",
    "    y = np.array(padded[end_row[i],end_row[i+1]])\n",
    "\n",
    "    # Optionally save the features to disk\n",
    "    np.save(f\"/Volumes/TOSHIBA EXT/north/{colonies[i]}-mfcc-augmented\", X)\n",
    "    np.save(f\"./data/{colonies[i]}-mfcc-augmented\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e4f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-Mel Spectrogram extraction\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "colonies = []\n",
    "frames_max = 0\n",
    "counter = 0\n",
    "total_samples = len(metadata)\n",
    "n_mels = 40\n",
    "\n",
    "for index, row in metadata.iterrows():\n",
    "    file_path = os.path.abspath(str(row[\"path\"]))\n",
    "    colony_label = row[\"colony\"]\n",
    "    state_label = row[\"state\"]\n",
    "\n",
    "    # Extract Log-Mel Spectrograms (do not add padding)\n",
    "    mels = librosa_trans.log_mel_spec_transform(file_path, mfcc_max_padding=0, n_mels=n_mels)\n",
    "    \n",
    "    # Save current frame count\n",
    "    num_frames = mels.shape[1]\n",
    "    \n",
    "    # Add row (feature / label)\n",
    "    features.append(mels)\n",
    "    labels.append(state_label)\n",
    "    colonies.append(colony_label)\n",
    "\n",
    "    # Update frames maximum\n",
    "    if (num_frames > frames_max):\n",
    "        frames_max = num_frames\n",
    "        \n",
    "    clear_output(wait=True)\n",
    "    print(\"Progress: {}/{}\".format(index+1, total_samples))\n",
    "    print(\"Last file: \", file_path)\n",
    "\n",
    "    counter += 1\n",
    "    \n",
    "print(\"Finished: {}/{}\".format(index, total_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eaf738",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = []\n",
    "\n",
    "# Add padding\n",
    "mels_max_padding = frames_max\n",
    "for i in range(len(features)):\n",
    "    size = len(features[i][0])\n",
    "    if (size < mels_max_padding):\n",
    "        pad_width = mels_max_padding - size\n",
    "        px = np.pad(features[i], \n",
    "                    pad_width=((0, 0), (0, pad_width)), \n",
    "                    mode='constant', \n",
    "                    constant_values=(0,))\n",
    "    \n",
    "    padded.append(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a061ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in len(end_row)-1:\n",
    "    X = np.array(padded[end_row[i],end_row[i+1]])\n",
    "    y = np.array(padded[end_row[i],end_row[i+1]])\n",
    "\n",
    "    # Optionally save the features to disk\n",
    "    np.save(f\"./data/{colonies[i]}-X-mel_spec-augmented\", X)\n",
    "    np.save(f\"./data/{colonies[i]}-y-mel_spec-augmented\", y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
